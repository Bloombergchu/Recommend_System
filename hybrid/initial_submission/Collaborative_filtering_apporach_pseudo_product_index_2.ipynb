{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit collaborative filtering approaches - pseudo product index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the development pipeline to apply the implicit item-based recommendation system algorithms for gracioustyle customers. The aim is to test and compare a few algorithms including  \n",
    "  \n",
    "* Alternating Least Square\n",
    "* Bayesian Personalized Ranking\n",
    "  \n",
    "The approaches above can be built into a hybrid CF approach, and further combined with the content based apporach as the optimized strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modified the modelling level to a pseudo product index concatenating product brand, type and color, instead of the actual product level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import random\n",
    "import implicit\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.datasets.movielens import get_movielens\n",
    "from implicit.lmf import LogisticMatrixFactorization\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight,tfidf_weight)\n",
    "import tqdm\n",
    "import codecs\n",
    "from tabulate import tabulate\n",
    "from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order data has been merged with product table to build a master source data in json/csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_data = pd.read_json('C:/Projects/DJ_projects/FP-growth/recommendation_engine/development/hybrid/data/customer_data_20201228.json') # This may take a couple minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143173 entries, 0 to 143172\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   CUSTOMER_DIM_KEY   143173 non-null  int64  \n",
      " 1   PRODUCT_DIM_KEY    143173 non-null  int64  \n",
      " 2   QUANTITY           143172 non-null  float64\n",
      " 3   PRODUCT_NAME       143166 non-null  object \n",
      " 4   COLOR              143173 non-null  object \n",
      " 5   PRODUCT_TYPE       143173 non-null  object \n",
      " 6   CATEGORY           143173 non-null  object \n",
      " 7   BRAND              143173 non-null  object \n",
      " 8   COLLECTION_ID      143173 non-null  object \n",
      " 9   RESOLUTION_STATUS  143173 non-null  object \n",
      " 10  ORDER_DATE_KEY     143173 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "retail_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143173, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUSTOMER_DIM_KEY     143173\n",
       "PRODUCT_DIM_KEY      143173\n",
       "QUANTITY             143172\n",
       "PRODUCT_NAME         143166\n",
       "COLOR                143173\n",
       "PRODUCT_TYPE         143173\n",
       "CATEGORY             143173\n",
       "BRAND                143173\n",
       "COLLECTION_ID        143173\n",
       "RESOLUTION_STATUS    143173\n",
       "ORDER_DATE_KEY       143173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pseudo product index combining the product type, brand and color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_DIM_KEY</th>\n",
       "      <th>PRODUCT_DIM_KEY</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>PRODUCT_TYPE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>RESOLUTION_STATUS</th>\n",
       "      <th>ORDER_DATE_KEY</th>\n",
       "      <th>PROD_INDEX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLLECTION_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-IN-1-DOWN</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABB12502</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABB12503</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBAL-FRESCO</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foliagedinner</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incantoturtdin</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simplyannagold</th>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simplyannaplat</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simplyannawhite</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6498 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CUSTOMER_DIM_KEY  PRODUCT_DIM_KEY  QUANTITY  PRODUCT_NAME  \\\n",
       "COLLECTION_ID                                                                \n",
       "11301                           5                5         5             5   \n",
       "3-IN-1-DOWN                     2                2         2             2   \n",
       "ABB12502                        4                4         4             4   \n",
       "ABB12503                       16               16        16            16   \n",
       "ABBAL-FRESCO                    4                4         4             4   \n",
       "...                           ...              ...       ...           ...   \n",
       "foliagedinner                  14               14        14            14   \n",
       "incantoturtdin                 31               31        31            31   \n",
       "simplyannagold                155              155       155           155   \n",
       "simplyannaplat                 11               11        11            11   \n",
       "simplyannawhite                15               15        15            15   \n",
       "\n",
       "                 COLOR  PRODUCT_TYPE  CATEGORY  BRAND  RESOLUTION_STATUS  \\\n",
       "COLLECTION_ID                                                              \n",
       "11301                5             5         5      5                  5   \n",
       "3-IN-1-DOWN          2             2         2      2                  2   \n",
       "ABB12502             4             4         4      4                  4   \n",
       "ABB12503            16            16        16     16                 16   \n",
       "ABBAL-FRESCO         4             4         4      4                  4   \n",
       "...                ...           ...       ...    ...                ...   \n",
       "foliagedinner       14            14        14     14                 14   \n",
       "incantoturtdin      31            31        31     31                 31   \n",
       "simplyannagold     155           155       155    155                155   \n",
       "simplyannaplat      11            11        11     11                 11   \n",
       "simplyannawhite     15            15        15     15                 15   \n",
       "\n",
       "                 ORDER_DATE_KEY  PROD_INDEX  \n",
       "COLLECTION_ID                                \n",
       "11301                         5           5  \n",
       "3-IN-1-DOWN                   2           2  \n",
       "ABB12502                      4           4  \n",
       "ABB12503                     16          16  \n",
       "ABBAL-FRESCO                  4           4  \n",
       "...                         ...         ...  \n",
       "foliagedinner                14          14  \n",
       "incantoturtdin               31          31  \n",
       "simplyannagold              155         155  \n",
       "simplyannaplat               11          11  \n",
       "simplyannawhite              15          15  \n",
       "\n",
       "[6498 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.groupby('COLLECTION_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_cols_old = ['PRODUCT_TYPE', 'BRAND', 'COLOR']\n",
    "retail_data['PROD_INDEX_old'] = retail_data[prod_cols_old].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "prod_cols = ['COLLECTION_ID', 'PRODUCT_TYPE', 'BRAND', 'COLOR']\n",
    "retail_data['PROD_INDEX'] = retail_data[prod_cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PROD_INDEX\n",
       "NO_COLLECTION_bath tumblers,drinking glasses_Mario Luca Giusti_Unknown    3295.0\n",
       "FELT-TABLE-LINER_table protectors_Gracious Style_White                    2989.0\n",
       "NO_COLLECTION_placemats_Kim Seybert_Unknown                               2816.0\n",
       "NO_COLLECTION_Unknown_Gracious Style_Unknown                              2673.0\n",
       "NO_COLLECTION_drinking glasses,bath tumblers_Mario Luca Giusti_Unknown    2478.0\n",
       "                                                                           ...  \n",
       "POMCROWN-DINNERWARE_serving bowls_Pom Pom at Home_Unknown                   -4.0\n",
       "POMCROWN-DINNERWARE_salad & dessert plates_Pom Pom at Home_Unknown          -6.0\n",
       "POMCROWN-DINNERWARE_dinner plates_Pom Pom at Home_Unknown                  -12.0\n",
       "POMCROWN-DINNERWARE_cereal & soup bowls_Pom Pom at Home_Unknown            -12.0\n",
       "NO_COLLECTION_Unknown_Anali_Cream                                          -15.0\n",
       "Name: QUANTITY, Length: 26018, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.groupby('PROD_INDEX')['QUANTITY'].agg('sum').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PROD_INDEX_old\n",
       "napkins_Garnier-Thiebaut_Unknown                            4085.0\n",
       "table protectors_Gracious Style_White                       3538.0\n",
       "bath tumblers,drinking glasses_Mario Luca Giusti_Unknown    3327.0\n",
       "placemats_Kim Seybert_Unknown                               2818.0\n",
       "dinner plates_Le Cadeaux_Unknown                            2806.0\n",
       "                                                             ...  \n",
       "serving bowls_Pom Pom at Home_Unknown                         -4.0\n",
       "salad & dessert plates_Pom Pom at Home_Unknown                -6.0\n",
       "cereal & soup bowls_Pom Pom at Home_Unknown                   -8.0\n",
       "dinner plates_Pom Pom at Home_Unknown                         -8.0\n",
       "Unknown_Anali_Cream                                          -15.0\n",
       "Name: QUANTITY, Length: 9501, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.groupby('PROD_INDEX_old')['QUANTITY'].agg('sum').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "table protectors_Gracious Style_White       3345\n",
       "tablecloths_Sferra_White                    1570\n",
       "detergents_Le Blanc_Unknown                 1520\n",
       "rugs_Dash & Albert_Unknown                  1483\n",
       "soap dispensers_Kassatex_Unknown            1389\n",
       "                                            ... \n",
       "dining tables_Interlude Home_Unknown           1\n",
       "baskets_Selamat_Unknown                        1\n",
       "coffee & tea pots_Chelsea House_Unknown        1\n",
       "buffet & chargers_Niderviller_Yellow           1\n",
       "bath sheets_Gracious Style_White/Lt Blue       1\n",
       "Name: PROD_INDEX_old, Length: 9501, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data['PROD_INDEX_old'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PROD_INDEX_old\n",
       "rugs_Dash & Albert_Unknown                     322\n",
       "tablecloths_Garnier-Thiebaut_Unknown           155\n",
       "tissue boxes_Pigeon & Poodle_Unknown           148\n",
       "waste baskets_Pigeon & Poodle_Unknown          133\n",
       "shams_Pine Cone Hill_Unknown                   130\n",
       "                                              ... \n",
       "pillow cases,bedding_Sferra_White / Salmon       1\n",
       "pillow cases,bedding_Sferra_White / Taupe        1\n",
       "pillow cases,bedding_Sferra_White / White        1\n",
       "pillow cases,bedding_Sferra_White/Aubergine      1\n",
       "hand towels_Kassatex_Skylight Blue               1\n",
       "Name: COLLECTION_ID, Length: 9501, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data.groupby('PROD_INDEX_old')['COLLECTION_ID'].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_DIM_KEY</th>\n",
       "      <th>PRODUCT_DIM_KEY</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>PRODUCT_TYPE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>COLLECTION_ID</th>\n",
       "      <th>RESOLUTION_STATUS</th>\n",
       "      <th>ORDER_DATE_KEY</th>\n",
       "      <th>PROD_INDEX</th>\n",
       "      <th>PROD_INDEX_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20067</th>\n",
       "      <td>69571</td>\n",
       "      <td>134333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Eloise Diamant Tablecloth 69\" x 69\" Green Swee...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>ELOISE-DIAMANT</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>ELOISE-DIAMANT</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>18371</td>\n",
       "      <td>ELOISE-DIAMANT_tablecloths_Garnier-Thiebaut_Un...</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86238</th>\n",
       "      <td>54636</td>\n",
       "      <td>333293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Round Around 64 in square  Tablecloth, Cappuccino</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>GTHRND-CAPPUCCINO</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>16678</td>\n",
       "      <td>GTHRND-CAPPUCCINO_tablecloths_Garnier-Thiebaut...</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69915</th>\n",
       "      <td>46535</td>\n",
       "      <td>186569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mille Datcha Aubergine Tablecloth 93\" Round, 1...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>MDATCHA-AUBERGINE</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>16017</td>\n",
       "      <td>MDATCHA-AUBERGINE_tablecloths_Garnier-Thiebaut...</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123505</th>\n",
       "      <td>34885</td>\n",
       "      <td>104583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Eloise Parchemin Tablecloth 69 x 120</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>NO_COLLECTION</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>15243</td>\n",
       "      <td>NO_COLLECTION_tablecloths_Garnier-Thiebaut_Unk...</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38415</th>\n",
       "      <td>87049</td>\n",
       "      <td>472794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mille Wax Ketchup Tablecloth 45\" x 45\" 100% Co...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>MWAX-KETCHUP</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>18529</td>\n",
       "      <td>MWAX-KETCHUP_tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61840</th>\n",
       "      <td>36395</td>\n",
       "      <td>134272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Comtesse Griotte Tablecloth Rect 69 x 120 in</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>NO_COLLECTION</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>15676</td>\n",
       "      <td>NO_COLLECTION_tablecloths_Garnier-Thiebaut_Unk...</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94566</th>\n",
       "      <td>58028</td>\n",
       "      <td>333247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Natte 90 in square Tablecloth, Ivory</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>GTHNATTE-IVORY</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>16989</td>\n",
       "      <td>GTHNATTE-IVORY_tablecloths_Garnier-Thiebaut_Un...</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51599</th>\n",
       "      <td>94068</td>\n",
       "      <td>134275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Isaphire Emeraude Tablecloth 69\" x 100\" Green ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>ISAPHIRE-EMERAUDE</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>ISAPHIRE-EMERAUDE</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>18617</td>\n",
       "      <td>ISAPHIRE-EMERAUDE_tablecloths_Garnier-Thiebaut...</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24744</th>\n",
       "      <td>81314</td>\n",
       "      <td>523661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Veneziano Sfumato Tablecloth 69\" x 120\" Green ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>GTH16695</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>18412</td>\n",
       "      <td>GTH16695_tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60740</th>\n",
       "      <td>37026</td>\n",
       "      <td>134348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Beauregard Ivoire Tablecloth 75\" x 146\" 100% C...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>tablecloths</td>\n",
       "      <td>BEAUREGARD-IVORY</td>\n",
       "      <td>Garnier-Thiebaut</td>\n",
       "      <td>BEAUREGARD-IVORY</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>15647</td>\n",
       "      <td>BEAUREGARD-IVORY_tablecloths_Garnier-Thiebaut_...</td>\n",
       "      <td>tablecloths_Garnier-Thiebaut_Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUSTOMER_DIM_KEY  PRODUCT_DIM_KEY  QUANTITY  \\\n",
       "20067              69571           134333       1.0   \n",
       "86238              54636           333293       0.0   \n",
       "69915              46535           186569       1.0   \n",
       "123505             34885           104583       1.0   \n",
       "38415              87049           472794       1.0   \n",
       "61840              36395           134272       0.0   \n",
       "94566              58028           333247       1.0   \n",
       "51599              94068           134275       1.0   \n",
       "24744              81314           523661       0.0   \n",
       "60740              37026           134348       1.0   \n",
       "\n",
       "                                             PRODUCT_NAME    COLOR  \\\n",
       "20067   Eloise Diamant Tablecloth 69\" x 69\" Green Swee...  Unknown   \n",
       "86238   Round Around 64 in square  Tablecloth, Cappuccino  Unknown   \n",
       "69915   Mille Datcha Aubergine Tablecloth 93\" Round, 1...  Unknown   \n",
       "123505               Eloise Parchemin Tablecloth 69 x 120  Unknown   \n",
       "38415   Mille Wax Ketchup Tablecloth 45\" x 45\" 100% Co...  Unknown   \n",
       "61840        Comtesse Griotte Tablecloth Rect 69 x 120 in  Unknown   \n",
       "94566                Natte 90 in square Tablecloth, Ivory  Unknown   \n",
       "51599   Isaphire Emeraude Tablecloth 69\" x 100\" Green ...  Unknown   \n",
       "24744   Veneziano Sfumato Tablecloth 69\" x 120\" Green ...  Unknown   \n",
       "60740   Beauregard Ivoire Tablecloth 75\" x 146\" 100% C...  Unknown   \n",
       "\n",
       "       PRODUCT_TYPE           CATEGORY             BRAND      COLLECTION_ID  \\\n",
       "20067   tablecloths     ELOISE-DIAMANT  Garnier-Thiebaut     ELOISE-DIAMANT   \n",
       "86238   tablecloths            Unknown  Garnier-Thiebaut  GTHRND-CAPPUCCINO   \n",
       "69915   tablecloths            Unknown  Garnier-Thiebaut  MDATCHA-AUBERGINE   \n",
       "123505  tablecloths            Unknown  Garnier-Thiebaut      NO_COLLECTION   \n",
       "38415   tablecloths            Unknown  Garnier-Thiebaut       MWAX-KETCHUP   \n",
       "61840   tablecloths            Unknown  Garnier-Thiebaut      NO_COLLECTION   \n",
       "94566   tablecloths            Unknown  Garnier-Thiebaut     GTHNATTE-IVORY   \n",
       "51599   tablecloths  ISAPHIRE-EMERAUDE  Garnier-Thiebaut  ISAPHIRE-EMERAUDE   \n",
       "24744   tablecloths            Unknown  Garnier-Thiebaut           GTH16695   \n",
       "60740   tablecloths   BEAUREGARD-IVORY  Garnier-Thiebaut   BEAUREGARD-IVORY   \n",
       "\n",
       "       RESOLUTION_STATUS  ORDER_DATE_KEY  \\\n",
       "20067          COMPLETED           18371   \n",
       "86238          COMPLETED           16678   \n",
       "69915          COMPLETED           16017   \n",
       "123505         COMPLETED           15243   \n",
       "38415          COMPLETED           18529   \n",
       "61840          COMPLETED           15676   \n",
       "94566          COMPLETED           16989   \n",
       "51599            PENDING           18617   \n",
       "24744          CANCELLED           18412   \n",
       "60740          COMPLETED           15647   \n",
       "\n",
       "                                               PROD_INDEX  \\\n",
       "20067   ELOISE-DIAMANT_tablecloths_Garnier-Thiebaut_Un...   \n",
       "86238   GTHRND-CAPPUCCINO_tablecloths_Garnier-Thiebaut...   \n",
       "69915   MDATCHA-AUBERGINE_tablecloths_Garnier-Thiebaut...   \n",
       "123505  NO_COLLECTION_tablecloths_Garnier-Thiebaut_Unk...   \n",
       "38415   MWAX-KETCHUP_tablecloths_Garnier-Thiebaut_Unknown   \n",
       "61840   NO_COLLECTION_tablecloths_Garnier-Thiebaut_Unk...   \n",
       "94566   GTHNATTE-IVORY_tablecloths_Garnier-Thiebaut_Un...   \n",
       "51599   ISAPHIRE-EMERAUDE_tablecloths_Garnier-Thiebaut...   \n",
       "24744       GTH16695_tablecloths_Garnier-Thiebaut_Unknown   \n",
       "60740   BEAUREGARD-IVORY_tablecloths_Garnier-Thiebaut_...   \n",
       "\n",
       "                              PROD_INDEX_old  \n",
       "20067   tablecloths_Garnier-Thiebaut_Unknown  \n",
       "86238   tablecloths_Garnier-Thiebaut_Unknown  \n",
       "69915   tablecloths_Garnier-Thiebaut_Unknown  \n",
       "123505  tablecloths_Garnier-Thiebaut_Unknown  \n",
       "38415   tablecloths_Garnier-Thiebaut_Unknown  \n",
       "61840   tablecloths_Garnier-Thiebaut_Unknown  \n",
       "94566   tablecloths_Garnier-Thiebaut_Unknown  \n",
       "51599   tablecloths_Garnier-Thiebaut_Unknown  \n",
       "24744   tablecloths_Garnier-Thiebaut_Unknown  \n",
       "60740   tablecloths_Garnier-Thiebaut_Unknown  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data[retail_data.PROD_INDEX_old == 'tablecloths_Garnier-Thiebaut_Unknown'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO_COLLECTION           67829\n",
       "FELT-TABLE-LINER         2885\n",
       "POINT-DINNERWARE          552\n",
       "LE-BAIN-BATH-ACCESS       462\n",
       "VIZCAYA-BATH-ACCESSO      461\n",
       "                        ...  \n",
       "MLIVIENNA                   1\n",
       "JPRMOY01                    1\n",
       "ABBLANDSCAPE-PAES           1\n",
       "PCHDALM-FLAN-PAJA           1\n",
       "SRAWAT5004                  1\n",
       "Name: COLLECTION_ID, Length: 6498, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_data['COLLECTION_ID'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4737555265308403"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67829/143173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data subseting has been done based on the following conditions,  \n",
    "  \n",
    "* Only contains the order history on products that have had orders since 2018. This is used as a proxy as the current product catelogue. \n",
    "* Resolution status in 'Completed' or 'Pending'.\n",
    "* De-duplicate the identical rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_retail = retail_data.loc[pd.isnull(retail_data.PRODUCT_NAME) == False]\n",
    "cleaned_retail = cleaned_retail[cleaned_retail['PRODUCT_DIM_KEY'].isin(cleaned_retail[cleaned_retail['ORDER_DATE_KEY'] > 17533].PRODUCT_DIM_KEY)]\n",
    "cleaned_retail['QUANTITY'] = cleaned_retail['QUANTITY'].fillna(0.0)\n",
    "cleaned_retail = cleaned_retail[cleaned_retail.RESOLUTION_STATUS.isin(['COMPLETED', 'PENDING'])]\n",
    "print('Duplicated rows: ' + str(cleaned_retail.duplicated().sum()))\n",
    "cleaned_retail.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_retail.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_retail['PROD_INDEX'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threhold function for cut-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_likes(df, uid_min, mid_min, user_column = 'CUSTOMER_DIM_KEY', item_column = 'PROD_INDEX'):\n",
    "    n_users = df[user_column].unique().shape[0]\n",
    "    n_items = df[item_column].unique().shape[0]\n",
    "    sparsity = float(df.shape[0]) / float(n_users*n_items) * 100\n",
    "    print('Starting likes info')\n",
    "    print('Number of users: {}'.format(n_users))\n",
    "    print('Number of models: {}'.format(n_items))\n",
    "    print('Sparsity: {:4.3f}%'.format(sparsity))\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        starting_shape = df.shape[0]\n",
    "        mid_counts = df.groupby(user_column)[item_column].count()\n",
    "        df = df[~df[user_column].isin(mid_counts[mid_counts < mid_min].index.tolist())]\n",
    "        uid_counts = df.groupby(item_column)[user_column].count()\n",
    "        df = df[~df[item_column].isin(uid_counts[uid_counts < uid_min].index.tolist())]\n",
    "        ending_shape = df.shape[0]\n",
    "        if starting_shape == ending_shape:\n",
    "            done = True\n",
    "    \n",
    "    assert(df.groupby(user_column)[item_column].count().min() >= mid_min)\n",
    "    assert(df.groupby(item_column)[user_column].count().min() >= uid_min)\n",
    "    \n",
    "    n_users = df[user_column].unique().shape[0]\n",
    "    n_items = df[item_column].unique().shape[0]\n",
    "    sparsity = float(df.shape[0]) / float(n_users*n_items) * 100\n",
    "    print('Ending likes info')\n",
    "    print('Number of users: {}'.format(n_users))\n",
    "    print('Number of models: {}'.format(n_items))\n",
    "    print('Sparsity: {:4.3f}%'.format(sparsity))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lim = threshold_likes(cleaned_retail, 2, 2)\n",
    "item_lookup = df_lim[['PROD_INDEX']].drop_duplicates() # Only get unique item/description pairs\n",
    "item_lookup['PROD_INDEX'] = item_lookup.PROD_INDEX.astype(str) # Encode as strings for future lookup ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-product matrix function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(cleaned_retail, row_feature, col_feature):\n",
    "    # cleaned_retail[row_feature] = cleaned_retail[row_feature].astype(int) # Convert to int for customer ID\n",
    "    cleaned_retail = cleaned_retail[[col_feature, 'QUANTITY', row_feature]] # Get rid of unnecessary info\n",
    "    grouped_cleaned = cleaned_retail.groupby([row_feature, col_feature]).sum().reset_index() # Group together\n",
    "    grouped_cleaned.QUANTITY.loc[grouped_cleaned.QUANTITY == 0] = 1 # Replace a sum of zero purchases with a one to\n",
    "    # indicate purchased\n",
    "    grouped_purchased = grouped_cleaned.query('QUANTITY > 0') # Only get customers where purchase totals were positive\n",
    "    \n",
    "    customers = list(np.sort(grouped_purchased[row_feature].unique())) # Get our unique customers\n",
    "    products = list(np.sort(grouped_purchased[col_feature].unique())) # Get our unique products that were purchased\n",
    "    quantity = list(grouped_purchased.QUANTITY) # All of our purchases\n",
    "    #print(products)\n",
    "    rows = grouped_purchased[row_feature].astype('category', CategoricalDtype(categories = customers)).cat.codes \n",
    "    # Get the associated row indices\n",
    "    cols = grouped_purchased[col_feature].astype('category', CategoricalDtype(categories = products)).cat.codes \n",
    "    # Get the associated column indices\n",
    "    purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))\n",
    "    return purchases_sparse, customers, products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create user-product matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_sparse, products, customers = create_matrix(df_lim, 'PROD_INDEX', 'CUSTOMER_DIM_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_arr = np.array(customers) # Array of customer IDs from the ratings matrix\n",
    "products_arr = np.array(products) # Array of product IDs from the ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(customers_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(products_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, product_users_altered = make_train(purchases_sparse, pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate AUC (evaluation metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr) \n",
    "\n",
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n",
    "def calc_mean_auc_cv(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n",
    "def calc_mean_auc_pop(training_set, altered_users, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    \n",
    "    return float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n",
    "'''\n",
    "param_grid = {'num_factors': [10, 20, 40, 80, 120],\n",
    "              'regularization': [0.0, 1e-5, 1e-3, 1e-1, 1e1, 1e2],\n",
    "              'alpha': [1, 10, 50, 100, 500, 1000]}\n",
    "'''\n",
    "\n",
    "param_grid = {'num_factors': [10, 20, 40, 80, 120],\n",
    "              'regularization': [0.0, 1e-5, 1e-3, 1e-1],\n",
    "              'alpha': [1, 10, 50, 100]}\n",
    "\n",
    "def cross_validation_als(sparse_matrix, model_name, param_grid, pct_test=0.2):\n",
    "    product_train, product_test, product_users_altered = make_train(sparse_matrix, pct_test = pct_test)\n",
    "    #product_train, product_out_test, product_users_out_altered = make_train(purchases_sparse, pct_test = 0.2)\n",
    "    #product_train, product_test, product_users_altered = make_train(product_train, pct_test = 0.2)\n",
    "    # item_vecs, user_vecs, model = train_model(training_set, model_name)\n",
    "    training_set = (bm25_weight(product_train, B=0.9)).tocsr()\n",
    "\n",
    "    model = AlternatingLeastSquares()\n",
    "    pop_auc = calc_mean_auc_pop(product_train, product_users_altered, product_test)\n",
    "\n",
    "    best_auc = 0\n",
    "    best_factors = 0\n",
    "    best_reg = 0\n",
    "    best_alpha = 0\n",
    "    best_model = model\n",
    "    print('The mean AUC of popularity benchmark: ', pop_auc)\n",
    "    for factor in param_grid['num_factors']:\n",
    "        for regu in param_grid['regularization']:\n",
    "            for alpha in param_grid['alpha']:\n",
    "                model = AlternatingLeastSquares(factors = factor, regularization = regu)\n",
    "                model.fit(training_set*alpha)\n",
    "                item_vecs = model.user_factors\n",
    "                user_vecs = model.item_factors\n",
    "                store_auc = calc_mean_auc_cv(product_train, product_users_altered, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)\n",
    "                print(factor, regu, alpha, store_auc)\n",
    "                \n",
    "                if store_auc > best_auc:\n",
    "                    best_auc = store_auc\n",
    "                    best_factors = factor\n",
    "                    best_reg = regu\n",
    "                    best_alpha = alpha\n",
    "                    best_model = model\n",
    "                    \n",
    "    print('Best AUC: ', best_auc)\n",
    "    print('Pop AUC: ', pop_auc)\n",
    "    print('Best factor: ', best_factors)\n",
    "    print('Best regularization: ', best_reg)\n",
    "    print('Best alpha: ', best_alpha)\n",
    "    return best_auc, pop_auc, best_factors, best_reg, best_alpha\n",
    "    # print(\"trained model '%s' in %s\", model_name, time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS hyper tuning with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_als = cross_validation_als(purchases_sparse, 'als', param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_als[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS hyper tuning distance parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlternatingLeastSquares(factors = cv_als[2], regularization = cv_als[3])\n",
    "# The literature suggests values between 0 and 3 for K1 and 0 and 1 for B. \n",
    "ratings = bm25_weight(product_train, K1 = 0.1, B = 1).tocsr()\n",
    "model.fit(ratings)\n",
    "item_vecs = model.user_factors\n",
    "user_vecs = model.item_factors\n",
    "store_auc, pop_auc = calc_mean_auc(product_train, product_users_altered, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)\n",
    "store_auc, pop_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'B': [0.1, 0.5, 1, 2, 3],\n",
    "              'K1': [0, 0.1, 0.01, 1]\n",
    "             }\n",
    "\n",
    "def cross_validation_als_bm25_param(sparse_matrix, model_name, param_grid, pct_test=0.2):\n",
    "    product_train, product_test, product_users_altered = make_train(sparse_matrix, pct_test = pct_test)\n",
    "    #product_train, product_out_test, product_users_out_altered = make_train(purchases_sparse, pct_test = 0.2)\n",
    "    #product_train, product_test, product_users_altered = make_train(product_train, pct_test = 0.2)\n",
    "    # item_vecs, user_vecs, model = train_model(training_set, model_name)\n",
    "    training_set = (bm25_weight(product_train, B=0.9)).tocsr()\n",
    "\n",
    "    model = AlternatingLeastSquares()\n",
    "    pop_auc = calc_mean_auc_pop(product_train, product_users_altered, product_test)\n",
    "    best_auc=0\n",
    "    best_B = 0\n",
    "    best_K1 = 0\n",
    "    best_model = model\n",
    "    print('The mean AUC of popularity benchmark: ', pop_auc)\n",
    "    for B in param_grid['B']:\n",
    "        for K1 in param_grid['K1']:\n",
    "            training_set = (bm25_weight(product_train, B=B,K1=K1)).tocsr()\n",
    "            model = AlternatingLeastSquares(factors = cv_als[2], regularization = cv_als[3])\n",
    "            model.fit(training_set)\n",
    "            item_vecs = model.user_factors\n",
    "            user_vecs = model.item_factors\n",
    "            store_auc = calc_mean_auc_cv(product_train, product_users_altered, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)\n",
    "            print(B, K1, store_auc)\n",
    "                \n",
    "            if store_auc > best_auc:\n",
    "                best_auc = store_auc\n",
    "                best_B = B\n",
    "                best_K1 = K1\n",
    "                best_model = model\n",
    "                    \n",
    "    print('Best AUC: ', best_auc)\n",
    "    print('Pop AUC: ', pop_auc)\n",
    "    print('Best B: ', best_B)\n",
    "    print('Best K1: ', best_K1)\n",
    "    return best_auc, pop_auc, best_B, best_K1, best_model\n",
    "    # print(\"trained model '%s' in %s\", model_name, time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_als_w = cross_validation_als_bm25_param(purchases_sparse, 'als', param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best ALS model from the hyper tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_als = cv_als_w[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR-MF hyper tuning with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "param_grid = {'num_factors': [10, 20, 40, 80, 120],\n",
    "              'learning_rate': [1, 0.1, 0.01, 0.001]\n",
    "              'regularization': [0.0, 0.1,0.01,0.001,0.0001,10],\n",
    "              'alpha': [1, 10, 50, 100, 500, 1000]}\n",
    "'''\n",
    "\n",
    "param_grid = {'num_factors': [10, 20, 40, 80, 120],\n",
    "              'learning_rate': [0.1],\n",
    "              'regularization': [0.0, 0.1,0.01,0.001],\n",
    "              'alpha': [1, 10, 50, 100, 500]}\n",
    "\n",
    "def cross_validation_bpr(sparse_matrix, model_name, param_grid, pct_test=0.2):\n",
    "    product_train, product_test, product_users_altered = make_train(sparse_matrix, pct_test = pct_test)\n",
    "    # item_vecs, user_vecs, model = train_model(training_set, model_name)\n",
    "    if model_name == \"bpr\":\n",
    "        model = BayesianPersonalizedRanking()\n",
    "    if model_name == \"lmf\":\n",
    "        model = LogisticMatrixFactorization()\n",
    "        \n",
    "    training_set = product_train\n",
    "    best_auc = 0\n",
    "    best_factors = 0\n",
    "    best_reg = 0\n",
    "    best_alpha = 0\n",
    "    best_learning_rate = 0\n",
    "\n",
    "    for factor in param_grid['num_factors']:\n",
    "        for regu in param_grid['regularization']:\n",
    "            for lr in param_grid['learning_rate']:\n",
    "                for alpha in param_grid['alpha']:\n",
    "                    model = BayesianPersonalizedRanking(factors = factor,learning_rate= lr, regularization = regu)\n",
    "                    model.fit(training_set*alpha)\n",
    "                    item_vecs = model.user_factors\n",
    "                    user_vecs = model.item_factors\n",
    "                    store_auc = calc_mean_auc_cv(product_train, product_users_altered, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)\n",
    "                    print(factor, regu, lr, alpha, store_auc, pop_auc)\n",
    "\n",
    "                    if store_auc > best_auc:\n",
    "                        best_auc = store_auc\n",
    "                        best_factors = factor\n",
    "                        best_reg = regu\n",
    "                        best_alpha = alpha\n",
    "                        best_learning_rate = lr\n",
    "                        best_model = model\n",
    "    print(best_auc, best_factors, best_learning_rate, best_reg, best_alpha)\n",
    "    return best_auc, best_factors,best_learning_rate, best_reg, best_alpha, best_model\n",
    "    # print(\"trained model '%s' in %s\", model_name, time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_bpr = cross_validation_bpr(purchases_sparse, 'bpr', param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best BPR-MF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best BPR model from the hyper tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bpr = cv_bpr[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_arr[5000:5100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get actual purchase vs model recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_items(model, customer_id, sparse_matrix, customer_list, item_list, item_lookup, num_items = 10):\n",
    "    cust_ind = np.where(customer_list == customer_id)[0][0] # Returns the index row of our customer id\n",
    "    purchased_ind = sparse_matrix[:,cust_ind].nonzero()[0] # Get column indices of purchased items\n",
    "    prod_codes = item_list[purchased_ind] # Get the stock codes for our purchased items\n",
    "    print(prod_codes)\n",
    "    purchased_items = item_lookup.loc[item_lookup.PROD_INDEX.isin(prod_codes)]\n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print('Print purchased items in train set')\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print(tabulate(purchased_items))\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print('Print full actual purchases above threshold')\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print(tabulate(df_lim[df_lim['CUSTOMER_DIM_KEY'] == customer_id], tablefmt=\"tsv\"))\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    print('Print model recommendations')\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    \n",
    "    recom = model.recommend(cust_ind, sparse_matrix.T.tocsr(),filter_items=purchased_ind.tolist(), N= num_items)\n",
    "    rec_keys = [] # start empty list to store items\n",
    "    descriptions = []\n",
    "    for index in recom:\n",
    "        key = item_list[index[0]]\n",
    "        rec_keys.append(key)\n",
    "        # descriptions.append(item_lookup.PRODUCT_NAME.loc[item_lookup.PRODUCT_DIM_KEY == key].iloc[0])\n",
    "        \n",
    "    scores = [item[1] for item in recom]\n",
    "    final_frame = pd.DataFrame({'PROD_INDEX': rec_keys, 'SCORE': scores}) # Create a dataframe \n",
    "    final_frame[['PROD_INDEX','SCORE']]\n",
    "    print(tabulate(final_frame, tablefmt=\"tsv\"))\n",
    "    return final_frame[['PROD_INDEX','SCORE']] # Switch order of columns around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 63356, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 63356, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 73183, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 73183, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 69065, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 69065, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 64522, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 64522, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 67130, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 67130, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 70154, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 70154, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 70731, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 70731, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 64041, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 64041, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 64489, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 64489, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_als, 68625, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_items(best_bpr, 68625, product_test, customers_arr, products_arr, item_lookup, num_items = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product index similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_item(model, item_id):\n",
    "    purchased_items = item_lookup.loc[item_lookup.PROD_INDEX.isin([item_id])]\n",
    "    item_ind = np.where(products_arr == item_id)\n",
    "    print(purchased_items)\n",
    "    arr = model.similar_items(item_ind[0][0], N=20)\n",
    "    rec_keys = [] # start empty list to store items\n",
    "    descriptions = []\n",
    "    for index in arr:\n",
    "        key = products_arr[index[0]]\n",
    "        rec_keys.append(key)\n",
    "        # descriptions.append(item_lookup.PRODUCT_NAME.loc[item_lookup.PRODUCT_DIM_KEY == key].iloc[0])\n",
    "        \n",
    "    scores = [item[1] for item in arr]\n",
    "    final_frame = pd.DataFrame({'PROD_INDEX': rec_keys, 'SCORE': scores}) # Create a dataframe \n",
    "    final_frame[['PROD_INDEX', 'SCORE']]\n",
    "    return final_frame[['PROD_INDEX','SCORE']] # Switch order of columns around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup.loc[item_lookup.PROD_INDEX.isin(['blankets_Pine Cone Hill_Unknown'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best ALS\n",
    "get_sim_item(model = best_als, item_id = 'blankets_Pine Cone Hill_Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best BPR-MF to rank similar product indexes\n",
    "get_sim_item(model = best_bpr, item_id = 'blankets_Pine Cone Hill_Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best BPR-MF to rank similar product indexes\n",
    "get_sim_item(model = best_bpr, item_id = 'table protectors_Gracious Style_White')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best BPR-MF to rank similar product indexes\n",
    "get_sim_item(model = best_bpr, item_id = 'detergents_Le Blanc_Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best BPR-MF to rank similar product indexes\n",
    "get_sim_item(model = best_bpr, item_id = 'salad & dessert plates_Anna Weatherley_Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
