{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import random\n",
    "import implicit\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from implicit.datasets.movielens import get_movielens\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.datasets.movielens import get_movielens\n",
    "from implicit.lmf import LogisticMatrixFactorization\n",
    "from implicit.nearest_neighbours import (BM25Recommender, CosineRecommender,\n",
    "                                         TFIDFRecommender, bm25_weight)\n",
    "import tqdm\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_data = pd.read_json('data/cus_user_quality_date_0716.json') # This may take a couple minutes\n",
    "# df2 = pd.read_csv('data/product_brand_type_color.csv') # This may take a couple minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120442 entries, 0 to 120441\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   CUSTOMER_DIM_KEY   120442 non-null  int64  \n",
      " 1   PRODUCT_DIM_KEY    120442 non-null  int64  \n",
      " 2   QUANTITY           120441 non-null  float64\n",
      " 3   PRODUCT_NAME       120435 non-null  object \n",
      " 4   COLOR              120442 non-null  object \n",
      " 5   PRODUCT_TYPE       120442 non-null  object \n",
      " 6   CATEGORY           120442 non-null  object \n",
      " 7   BRAND              120442 non-null  object \n",
      " 8   RESOLUTION_STATUS  120442 non-null  object \n",
      " 9   ORDER_DATE_KEY     120442 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "retail_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retail_data[retail_data['PRODUCT_DIM_KEY'].isin(retail_data[retail_data['ORDER_DATE_KEY'] > 17533].PRODUCT_DIM_KEY)]\n",
    "#cleaned_retail[cleaned_retail['ORDER_DATE_KEY'] > 17533]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows: 272\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_DIM_KEY</th>\n",
       "      <th>PRODUCT_DIM_KEY</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>PRODUCT_TYPE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>RESOLUTION_STATUS</th>\n",
       "      <th>ORDER_DATE_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60189</td>\n",
       "      <td>128674</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Montana blanket sham european</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>blankets,shams</td>\n",
       "      <td>MONTANA-BLANKET</td>\n",
       "      <td>Pine Cone Hill</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>17178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60189</td>\n",
       "      <td>128673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Montana blanket full/queen</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>blankets</td>\n",
       "      <td>MONTANA-BLANKET</td>\n",
       "      <td>Pine Cone Hill</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>17178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57104</td>\n",
       "      <td>336148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sago Palm Bread Plate Gold</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>bread &amp; butter plates</td>\n",
       "      <td>MICHAEL-ARAM</td>\n",
       "      <td>Michael Aram</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>17178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60157</td>\n",
       "      <td>180079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Butterfly Garden Canape Dish, Porcelain 4 3/4 ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>canape plates</td>\n",
       "      <td>CHIP-AND-DIP</td>\n",
       "      <td>Rosenthal</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>17177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60177</td>\n",
       "      <td>398086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Verum Shiny Nickel Soap Dish Rectangular Taper...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>soap dishes</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Pigeon &amp; Poodle</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>17176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120370</th>\n",
       "      <td>83371</td>\n",
       "      <td>544613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Benidorm Melamine Gift Set Spoon Rest With Mat...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>kitchen towels,spoon rests</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Le Cadeaux</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>18450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120373</th>\n",
       "      <td>64185</td>\n",
       "      <td>498818</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bel Air 20 x 20 in Napkins Lime, Set of Four</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>napkins</td>\n",
       "      <td>Zalto</td>\n",
       "      <td>Mode Living</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>18451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120388</th>\n",
       "      <td>83223</td>\n",
       "      <td>558036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Aegean Small Pedestal Bowl in Rough Matte Whit...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>JAMIE-YOUNG</td>\n",
       "      <td>Jamie Young</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>18451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120394</th>\n",
       "      <td>64185</td>\n",
       "      <td>498818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bel Air 20 x 20 in Napkins Lime, Set of Four</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>napkins</td>\n",
       "      <td>Zalto</td>\n",
       "      <td>Mode Living</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>18451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120395</th>\n",
       "      <td>82865</td>\n",
       "      <td>579090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Venice Washcloth 12 x 12 in Grey</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>wash cloths</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Graccioza</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>18447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48715 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUSTOMER_DIM_KEY  PRODUCT_DIM_KEY  QUANTITY  \\\n",
       "0                  60189           128674       2.0   \n",
       "1                  60189           128673       1.0   \n",
       "2                  57104           336148       1.0   \n",
       "5                  60157           180079       1.0   \n",
       "8                  60177           398086       1.0   \n",
       "...                  ...              ...       ...   \n",
       "120370             83371           544613       1.0   \n",
       "120373             64185           498818       2.0   \n",
       "120388             83223           558036       1.0   \n",
       "120394             64185           498818       1.0   \n",
       "120395             82865           579090       2.0   \n",
       "\n",
       "                                             PRODUCT_NAME    COLOR  \\\n",
       "0                           Montana blanket sham european  Unknown   \n",
       "1                              Montana blanket full/queen  Unknown   \n",
       "2                              Sago Palm Bread Plate Gold  Unknown   \n",
       "5       Butterfly Garden Canape Dish, Porcelain 4 3/4 ...  Unknown   \n",
       "8       Verum Shiny Nickel Soap Dish Rectangular Taper...  Unknown   \n",
       "...                                                   ...      ...   \n",
       "120370  Benidorm Melamine Gift Set Spoon Rest With Mat...  Unknown   \n",
       "120373       Bel Air 20 x 20 in Napkins Lime, Set of Four  Unknown   \n",
       "120388  Aegean Small Pedestal Bowl in Rough Matte Whit...  Unknown   \n",
       "120394       Bel Air 20 x 20 in Napkins Lime, Set of Four  Unknown   \n",
       "120395                   Venice Washcloth 12 x 12 in Grey  Unknown   \n",
       "\n",
       "                      PRODUCT_TYPE         CATEGORY            BRAND  \\\n",
       "0                   blankets,shams  MONTANA-BLANKET   Pine Cone Hill   \n",
       "1                         blankets  MONTANA-BLANKET   Pine Cone Hill   \n",
       "2            bread & butter plates     MICHAEL-ARAM     Michael Aram   \n",
       "5                    canape plates     CHIP-AND-DIP        Rosenthal   \n",
       "8                      soap dishes          Unknown  Pigeon & Poodle   \n",
       "...                            ...              ...              ...   \n",
       "120370  kitchen towels,spoon rests          Unknown       Le Cadeaux   \n",
       "120373                     napkins            Zalto      Mode Living   \n",
       "120388                     Unknown      JAMIE-YOUNG      Jamie Young   \n",
       "120394                     napkins            Zalto      Mode Living   \n",
       "120395                 wash cloths          Unknown        Graccioza   \n",
       "\n",
       "       RESOLUTION_STATUS  ORDER_DATE_KEY  \n",
       "0              COMPLETED           17178  \n",
       "1              COMPLETED           17178  \n",
       "2              COMPLETED           17178  \n",
       "5              COMPLETED           17177  \n",
       "8              COMPLETED           17176  \n",
       "...                  ...             ...  \n",
       "120370         COMPLETED           18450  \n",
       "120373         COMPLETED           18451  \n",
       "120388         COMPLETED           18451  \n",
       "120394         COMPLETED           18451  \n",
       "120395         COMPLETED           18447  \n",
       "\n",
       "[48715 rows x 10 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_retail = retail_data.loc[pd.isnull(retail_data.PRODUCT_NAME) == False]\n",
    "cleaned_retail = cleaned_retail[cleaned_retail['PRODUCT_DIM_KEY'].isin(cleaned_retail[cleaned_retail['ORDER_DATE_KEY'] > 17533].PRODUCT_DIM_KEY)]\n",
    "cleaned_retail['QUANTITY'] = cleaned_retail['QUANTITY'].fillna(0.0)\n",
    "cleaned_retail = cleaned_retail[cleaned_retail['RESOLUTION_STATUS'] == 'COMPLETED']\n",
    "print('Duplicated rows: ' + str(cleaned_retail.duplicated().sum()))\n",
    "cleaned_retail.drop_duplicates(inplace=True)\n",
    "cleaned_retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48715 entries, 0 to 120395\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CUSTOMER_DIM_KEY   48715 non-null  int64  \n",
      " 1   PRODUCT_DIM_KEY    48715 non-null  int64  \n",
      " 2   QUANTITY           48715 non-null  float64\n",
      " 3   PRODUCT_NAME       48715 non-null  object \n",
      " 4   COLOR              48715 non-null  object \n",
      " 5   PRODUCT_TYPE       48715 non-null  object \n",
      " 6   CATEGORY           48715 non-null  object \n",
      " 7   BRAND              48715 non-null  object \n",
      " 8   RESOLUTION_STATUS  48715 non-null  object \n",
      " 9   ORDER_DATE_KEY     48715 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_retail.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_lookup = cleaned_retail[['PRODUCT_TYPE', 'PRODUCT_NAME']].drop_duplicates() # Only get unique item/description pairs\n",
    "#item_lookup['PRODUCT_DIM_KEY'] = item_lookup.PRODUCT_DIM_KEY.astype(str) # Encode as strings for future lookup ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_likes(df, uid_min, mid_min, user_column = 'CUSTOMER_DIM_KEY', item_column = 'PRODUCT_TYPE'):\n",
    "    n_users = df[user_column].unique().shape[0]\n",
    "    n_items = df[item_column].unique().shape[0]\n",
    "    sparsity = float(df.shape[0]) / float(n_users*n_items) * 100\n",
    "    print('Starting likes info')\n",
    "    print('Number of users: {}'.format(n_users))\n",
    "    print('Number of models: {}'.format(n_items))\n",
    "    print('Sparsity: {:4.3f}%'.format(sparsity))\n",
    "    \n",
    "    done = False\n",
    "    while not done:\n",
    "        starting_shape = df.shape[0]\n",
    "        mid_counts = df.groupby(user_column)[item_column].count()\n",
    "        df = df[~df[user_column].isin(mid_counts[mid_counts < mid_min].index.tolist())]\n",
    "        uid_counts = df.groupby(item_column)[user_column].count()\n",
    "        df = df[~df[item_column].isin(uid_counts[uid_counts < uid_min].index.tolist())]\n",
    "        ending_shape = df.shape[0]\n",
    "        if starting_shape == ending_shape:\n",
    "            done = True\n",
    "    \n",
    "    assert(df.groupby(user_column)[item_column].count().min() >= mid_min)\n",
    "    assert(df.groupby(item_column)[user_column].count().min() >= uid_min)\n",
    "    \n",
    "    n_users = df[user_column].unique().shape[0]\n",
    "    n_items = df[item_column].unique().shape[0]\n",
    "    sparsity = float(df.shape[0]) / float(n_users*n_items) * 100\n",
    "    print('Ending likes info')\n",
    "    print('Number of users: {}'.format(n_users))\n",
    "    print('Number of models: {}'.format(n_items))\n",
    "    print('Sparsity: {:4.3f}%'.format(sparsity))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting likes info\n",
      "Number of users: 25852\n",
      "Number of models: 954\n",
      "Sparsity: 0.198%\n",
      "Ending likes info\n",
      "Number of users: 25852\n",
      "Number of models: 954\n",
      "Sparsity: 0.198%\n"
     ]
    }
   ],
   "source": [
    "df_lim = threshold_likes(cleaned_retail, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(cleaned_retail, row_feature, col_feature):\n",
    "    cleaned_retail[row_feature] = cleaned_retail[row_feature].astype(int) # Convert to int for customer ID\n",
    "    cleaned_retail = cleaned_retail[[col_feature, 'QUANTITY', row_feature]] # Get rid of unnecessary info\n",
    "    grouped_cleaned = cleaned_retail.groupby([row_feature, col_feature]).sum().reset_index() # Group together\n",
    "    grouped_cleaned.QUANTITY.loc[grouped_cleaned.QUANTITY == 0] = 1 # Replace a sum of zero purchases with a one to\n",
    "    # indicate purchased\n",
    "    grouped_purchased = grouped_cleaned.query('QUANTITY > 0') # Only get customers where purchase totals were positive\n",
    "    \n",
    "    customers = list(np.sort(grouped_purchased[row_feature].unique())) # Get our unique customers\n",
    "    products = list(grouped_purchased[col_feature].unique()) # Get our unique products that were purchased\n",
    "    quantity = list(grouped_purchased.QUANTITY) # All of our purchases\n",
    "\n",
    "    rows = grouped_purchased[row_feature].astype('category', CategoricalDtype(categories = customers)).cat.codes \n",
    "    # Get the associated row indices\n",
    "    cols = grouped_purchased[col_feature].astype('category', CategoricalDtype(categories = products)).cat.codes \n",
    "    # Get the associated column indices\n",
    "    purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))\n",
    "    return purchases_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "cleaned_retail['CUSTOMER_DIM_KEY'] = cleaned_retail['CUSTOMER_DIM_KEY'].astype(int) # Convert to int for customer ID\n",
    "cleaned_retail = cleaned_retail[['PRODUCT_TYPE', 'QUANTITY', 'CUSTOMER_DIM_KEY']] # Get rid of unnecessary info\n",
    "grouped_cleaned = cleaned_retail.groupby(['CUSTOMER_DIM_KEY', 'PRODUCT_TYPE']).sum().reset_index() # Group together\n",
    "grouped_cleaned.QUANTITY.loc[grouped_cleaned.QUANTITY == 0] = 1 # Replace a sum of zero purchases with a one to\n",
    "# indicate purchased\n",
    "grouped_purchased = grouped_cleaned.query('QUANTITY > 0') # Only get customers where purchase totals were positive\n",
    "\n",
    "customers = list(np.sort(grouped_purchased['CUSTOMER_DIM_KEY'].unique())) # Get our unique customers\n",
    "products = list(grouped_purchased['PRODUCT_TYPE'].unique()) # Get our unique products that were purchased\n",
    "quantity = list(grouped_purchased.QUANTITY) # All of our purchases\n",
    "\n",
    "rows = grouped_purchased.CUSTOMER_DIM_KEY.astype('category', CategoricalDtype(categories = customers)).cat.codes \n",
    "# Get the associated row indices\n",
    "cols = grouped_purchased.PRODUCT_TYPE.astype('category', CategoricalDtype(categories = products)).cat.codes \n",
    "# Get the associated column indices\n",
    "purchases_sparse = sparse.csr_matrix((quantity, (rows, cols)), shape=(len(customers), len(products)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_sparse = create_matrix(df_lim, 'CUSTOMER_DIM_KEY', 'PRODUCT_TYPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_train, product_test, product_users_altered = make_train(purchases_sparse, pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_model(ratings, model_name, factors =20, regularization=0.1,alpha = 10):\n",
    "    # lets weight these models by bm25weight.\n",
    "\n",
    "    if model_name == \"als\":\n",
    "        model = AlternatingLeastSquares(factors =factors, regularization=regularization)\n",
    "        print(\"weighting matrix by bm25_weight\")\n",
    "        ratings = (bm25_weight(ratings, B=0.9) * 5).tocsr()\n",
    "    elif model_name == \"bpr\":\n",
    "        model = BayesianPersonalizedRanking()\n",
    "\n",
    "    elif model_name == \"lmf\":\n",
    "        model = LogisticMatrixFactorization()\n",
    "\n",
    "    elif model_name == \"tfidf\":\n",
    "        model = TFIDFRecommender()\n",
    "\n",
    "    elif model_name == \"cosine\":\n",
    "        model = CosineRecommender()\n",
    "\n",
    "    elif model_name == \"bm25\":\n",
    "        model = BM25Recommender(B=0.2)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"TODO: model %s\" % model_name)\n",
    "    # train the model\n",
    "    print(\"training model %s\", model_name)\n",
    "    start = time.time()\n",
    "    model.fit(ratings*alpha)\n",
    "    print(\"trained model '%s' in %s\", model_name, time.time() - start)\n",
    "        \n",
    "    item_vecs = model.user_factors\n",
    "    user_vecs = model.item_factors\n",
    "    return item_vecs, user_vecs, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighting matrix by bm25_weight\n",
      "training model %s als\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91af4391aa704900a92695c9bcf855f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trained model '%s' in %s als 0.3192934989929199\n"
     ]
    }
   ],
   "source": [
    "item_vecs, user_vecs, model = train_model(product_train, 'als')\n",
    "store_auc, pop_auc = calc_mean_auc(product_train, product_users_altered, [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.715, 0.956)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_auc, pop_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
